# Joseph McInerney MSc AI Project

## Part 1: Pretraining
- Preprocessing: containment, CNG, , UCCIX, Bitext 
- Training Script
    - Dependencies
    - Bash Script
    - Continued Pre-training Script
    - Distributed Training Config

## Part 2: Instruction Tuning
- API Calls to Generate LLM Instruct-Response pairs
- App for Human Annotation
- LLM Automated Annotation
- Ranking and Inter-Annotator Analysis
    - Bradley Terry Ranking and Cohen's Kappa Script
    - Dependencies
- Dataset preparationg for Google Vertext AI Translation of Dolly V2  
- Statistical Analysis of Open-Ended Response Lengths
- Dataset: HF_REPO

## Part 2: Human Feedback Daat
- LIMA Translation and Preference Dataset Creation: create_hf_LIMA_ga.py
- App for Native Annotation: annotate_preferences.py
- Dataset: HF_REPO
